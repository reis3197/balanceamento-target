# balanceamento-target
üìä Machine Learning: A import√¢ncia de balancear a vari√°vel Target em modelos de classifica√ß√£o ü§ñ

Hoje quero compartilhar um tema essencial para quem trabalha com modelos de classifica√ß√£o em Machine Learning: o balanceamento da vari√°vel Target.

üîé Quando criamos um modelo de classifica√ß√£o, a vari√°vel alvo (ou Target) √© aquela que queremos prever, geralmente representada por valores como "Sim ou N√£o", "True ou False" ou simplesmente 0 e 1.
Mas voc√™ sabia que, se essa vari√°vel estiver desbalanceada, seu modelo pode ficar completamente enviesado? Isso acontece porque, em casos de forte desbalanceamento (por exemplo, 95% das amostras sendo "N√£o" e apenas 5% sendo "Sim"), o modelo pode aprender a simplesmente prever sempre a classe majorit√°ria ‚Äî e, mesmo assim, obter uma alta acur√°cia. Por√©m, esse resultado √© ilus√≥rio e prejudica a qualidade da previs√£o.

‚ö†Ô∏è Quais problemas o desbalanceamento pode causar?
Modelos enviesados que ignoram a classe minorit√°ria.
M√©tricas como acur√°cia se tornam enganosas.
Menor capacidade de generaliza√ß√£o do modelo.

‚úÖ Como resolver isso? Existem v√°rias t√©cnicas para balancear a vari√°vel Target, como:

Oversampling: aumentar artificialmente a quantidade de registros da classe minorit√°ria.
Undersampling: reduzir a quantidade de registros da classe majorit√°ria.
SMOTE: t√©cnica de oversampling que cria novos exemplos sint√©ticos da classe minorit√°ria.

Se voc√™ trabalha com Data Science, An√°lise de Dados ou Machine Learning, vale sempre conferir como est√° a distribui√ß√£o da sua vari√°vel alvo antes de treinar o modelo. Um pequeno ajuste nesse ponto pode fazer toda a diferen√ßa nos resultados!
